---
layout: post
title:  "Linear Regression Explained"
categories: [ds/ai/ml]
permalink: /:year/:month/:day/:title:output_ext
---

### Building an intuitive understanding of how Linear Regression works and how it leads to Gradient Descent.
**Reference**: How a straight line teaches machines to learn. [https://briefer.cloud/blog/posts/least-squares/](https://briefer.cloud/blog/posts/least-squares/) 

#### Notes
**Slope** Sets the tilt of the line. As the tilt increases, y-variable/x-variable increases. e.g. Price/Sq.Ft.  
**Intercept** Shifts the line up or down in the graph or where the line starts.  It sets the baseline value. e.g. starting value of home.  
**Error** Represents how far are we from the actual value.  
**Absolute Error** treats all the error magnitudes the same. Two medium errors is same as one big one.  
**Non-Linear Scale** Squaring errors cause big errors to be bigger and hence the error line will be non-linear



